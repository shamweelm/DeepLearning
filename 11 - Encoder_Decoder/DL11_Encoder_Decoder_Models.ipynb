{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL11 Encoder_Decoder_Models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSo9UiBS9Fmk"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Instantiates the device to be used as GPU/CPU based on availability\n",
        "device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Visualization tools\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import random"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnpLxKnfANj_"
      },
      "source": [
        "# Data Management"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpPIluxSCqbA"
      },
      "source": [
        "### Alphabets Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xh2RV5e_Cr23"
      },
      "source": [
        "Converting the English alphabets to it's one hot encoding format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkjZ9Sj3AP_j",
        "outputId": "fcbdfc0c-68a4-44bf-e493-3f6cdc229f13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "eng_alphabets = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "pad_char = '-PAD-'\n",
        "\n",
        "eng_alpha2index = { pad_char : 0}\n",
        "for index,char in enumerate(eng_alphabets):\n",
        "    eng_alpha2index[char] = index + 1\n",
        "\n",
        "print(eng_alpha2index)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGZ9vZRzFOcz"
      },
      "source": [
        "Converting the Hindi alphabets from Unicode to it's one hot encoding format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FgM4qlRDiKG",
        "outputId": "7d6d9558-9bcb-49e3-98fb-457704d73c6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Hindi Unicode Hex Range is 2304:2432. Source: https://en.wikipedia.org/wiki/Devanagari_(Unicode_block)\n",
        "\n",
        "hindi_alphabets = [ chr(alpha) for alpha in range(2304, 2432)]\n",
        "hindi_alphabets_size = len(hindi_alphabets)\n",
        "\n",
        "hindi_alpha2index = { pad_char : 0}\n",
        "for index,char in enumerate(hindi_alphabets):\n",
        "    hindi_alpha2index[char] = index + 1\n",
        "\n",
        "print(hindi_alpha2index)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5a0VhZaFLWl"
      },
      "source": [
        "### Helper functions for data pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBe0xwl0FMPt"
      },
      "source": [
        "import re\n",
        "\n",
        "# Removing all non-English letters.\n",
        "not_eng_letters_regex = re.compile('[^a-zA-Z ]')\n",
        "\n",
        "def cleanEnglishVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ').upper()     # Replacing - and , and convering to uppercase.\n",
        "    line = not_eng_letters_regex.sub('', line)                  # Substitute anything not in list of english characters with nothing i.e. ''\n",
        "    return line.split()\n",
        "\n",
        "# Remove all Hindi non-letters.\n",
        "def cleanHindiVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ').upper()     # Replacing - and , and convering to uppercase.\n",
        "    cleaned_line = ''\n",
        "    # Check if the char is in the valid Hindi Unicode range and add them to cleaned_line.\n",
        "    for char in line:\n",
        "        if char in hindi_alpha2index or char == ' ':    \n",
        "            cleaned_line += char\n",
        "    return cleaned_line.split()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkNbRSaGguJ5"
      },
      "source": [
        "### Dataset Loading from XML File."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE9uDunzf-PY"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "class TransliterationDataLoader(Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.eng_words, self.hindi_words = self.readXmlDataset(filename, cleanHindiVocab)\n",
        "        self.shuffle_indices = list(range(len(self.eng_words)))\n",
        "        random.shuffle(self.shuffle_indices)\n",
        "        self.shuffle_start_index = 0\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.eng_words)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.eng_words[idx], self.hindi_words[idx]\n",
        "    \n",
        "    def readXmlDataset(self, filename, lang_vocab_cleaner):\n",
        "        transliterationCorpus = ET.parse(filename).getroot()\n",
        "        lang1_words = []\n",
        "        lang2_words = []\n",
        "\n",
        "        for line in transliterationCorpus:\n",
        "            wordlist1 = cleanEnglishVocab(line[0].text)\n",
        "            wordlist2 = lang_vocab_cleaner(line[1].text)\n",
        "\n",
        "            # Skip noisy data\n",
        "            if len(wordlist1) != len(wordlist2):\n",
        "                print('Skipping: ', line[0].text, ' - ', line[1].text)\n",
        "                continue\n",
        "\n",
        "            for word in wordlist1:\n",
        "                lang1_words.append(word)\n",
        "            for word in wordlist2:\n",
        "                lang2_words.append(word)\n",
        "\n",
        "        return lang1_words, lang2_words\n",
        "    \n",
        "    def get_random_sample(self):\n",
        "        return self.__getitem__(np.random.randint(len(self.eng_words)))\n",
        "    \n",
        "    def get_batch_from_array(self, batch_size, array):\n",
        "        end = self.shuffle_start_index + batch_size\n",
        "        batch = []\n",
        "        if end >= len(self.eng_words):\n",
        "            batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_words)]]\n",
        "            end = len(self.eng_words)\n",
        "        return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index : end]]\n",
        "    \n",
        "    def get_batch(self, batch_size, postprocess = True):\n",
        "        eng_batch = self.get_batch_from_array(batch_size, self.eng_words)\n",
        "        hindi_batch = self.get_batch_from_array(batch_size, self.hindi_words)\n",
        "        self.shuffle_start_index += batch_size + 1\n",
        "        \n",
        "        # Reshuffle if 1 epoch is complete\n",
        "        if self.shuffle_start_index >= len(self.eng_words):\n",
        "            random.shuffle(self.shuffle_indices)\n",
        "            self.shuffle_start_index = 0\n",
        "            \n",
        "        return eng_batch, hindi_batch"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSB9hFgBpcpf",
        "outputId": "27884f85-7375-44b2-f1a7-5f7ff217cdfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "train_data = TransliterationDataLoader('NEWS2012-Training-EnHi-13937.xml')\n",
        "test_data = TransliterationDataLoader('NEWS2012-Ref-EnHi-1000.xml')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skipping:  BARHARWA JUNCTION  -  बरहरवा\n",
            "Skipping:  STATE BNK TR  -  स्टेट बैंक ऑफ त्रावणकोर\n",
            "Skipping:  SOUTH ARLINGTON CHURCH OF CHRIST  -  साउथ अर्लिंग्टन\n",
            "Skipping:  KING EDWARD VII  -  किंग एडवर्ड\n",
            "Skipping:  DIBANG VALLEY  -  दिबंगवैली\n",
            "Skipping:  ORDER OF VASA  -  ऑडर ऑफ़ द वासा\n",
            "Skipping:  AZAMNAGAR ROAD  -  आज़मनगर\n",
            "Skipping:  CAPE TOWN  -  केपटाउन\n",
            "Skipping:  NEW ZEALAND  -  न्यूज़ीलैंड\n",
            "Skipping:  SEA OF THE HEBRIDES  -  सी ऑफ हरब्रिड्‍स\n",
            "Skipping:  RAMCOIND  -  राम्को इंड\n",
            "Skipping:  KELVINGROVE ART GALLERY AND MUSEUM  -  केल्व‍िनग्रोव आर्ट एण्ड म्युज़ियम\n",
            "Skipping:  AUSTRALIAN NATIONAL UNIVERSITY  -  ऑस्ट्रेलियननेशनल यूनिवर्सिटी\n",
            "Skipping:  JAHAN AARA  -  जहाँआरा\n",
            "Skipping:  NAVABHARAT FERRO ALLOYS  -  नव भारत फ़ैरो अलॉय\n",
            "Skipping:  RAMA LINGESHWARA  -  रामालिंगेश्वर\n",
            "Skipping:  FAKHRUN NISA  -  फखरुन्निसा\n",
            "Skipping:  REDIFF.COM INDIA LIMITED  -  रेडिफ़ डॉट कॉम इंडिया लिमिटेड\n",
            "Skipping:  OMKARNATH THAKUR  -  ओंकार नाथ ठाकुर\n",
            "Skipping:  OPENTV  -  ओपन टीवी\n",
            "Skipping:  ENVOY COMMUNICATIONS GROUP  -  एन्वॉय कम्युनिकेशंस\n",
            "Skipping:  WAR OF THE HOLY LEAGUE  -  वार ऑफ होली लीग\n",
            "Skipping:  VAPARAISO CHURCH OF CHRIST  -  व्हापरासिओ\n",
            "Skipping:  PARIS CHARLES DE GAULLE  -  पेरिस रॉसे चार्ल्स डे ग्यूले\n",
            "Skipping:  PARKWAY APOSTOLIC  -  पार्क वे अपोस्टोलिक\n",
            "Skipping:  MAUNA LOA  -  मौनालोआ\n",
            "Skipping:  MASS MUTUAL LIFE  -  मास म्युच्युअल लाइफ़ इंश्योरेंस\n",
            "Skipping:  STATS CHIPPAC  -  स्टेट्सचिपपैक\n",
            "Skipping:  NEWFOUNDLAND  -  न्यू फाउंडलैंड\n",
            "Skipping:  LONDONHEATHROW  -  लंदन हीथ्रो\n",
            "Skipping:  RETALIX  -  रेटालिक्स लि.\n",
            "Skipping:  SRISAILAM  -  श्री शैलम\n",
            "Skipping:  KARA-KUM  -  काराकुम\n",
            "Skipping:  WIND RIVER  -  विंडरिवर\n",
            "Skipping:  NETAJI SUBHASH CHANDRA BOSE  -  नेताजी सुभाषचंद्र बोस\n",
            "Skipping:  ROCKBROOK UNITED  -  रॉकब्रुक यूनाइटेड मेथोडिस्ट\n",
            "Skipping:  WALTER SCOTT  -  वॉल्टरस्कॉट\n",
            "Skipping:  COLOURPLUS FASHIONS  -  कलर प्लस फ़ैशन्स\n",
            "Skipping:  BAL KRISHNA  -  बालकृष्णा\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvM41zuosjrE"
      },
      "source": [
        "### Basic Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmahxuVHsnmD",
        "outputId": "96dc830d-1761-4f0c-cfd6-226679370530",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "print(\"Train Set Size:\\t\", len(train_data))\n",
        "print(\"Test Set Size:\\t\", len(test_data))\n",
        "\n",
        "print('\\nSample data from train-set:')\n",
        "for i in range(10):\n",
        "    eng, hindi = train_data.get_random_sample()\n",
        "    print(eng + ' ' + hindi)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set Size:\t 20543\n",
            "Test Set Size:\t 1000\n",
            "\n",
            "Sample data from train-set:\n",
            "ZOLTIN ज़ोल्टिन\n",
            "DHARNAODA धरनौदा\n",
            "SARANGA सारंग\n",
            "INDAL इंडल\n",
            "EK एक\n",
            "HARRIS हैरीस\n",
            "YUVARAAJ युवराज\n",
            "MELVA मेल्वा\n",
            "APNA अपना\n",
            "BALIDAN बलिदान\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daEHxnbctzdA"
      },
      "source": [
        "### Encoding the words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWMl1iHDtEPg"
      },
      "source": [
        "# One hot Representation of English word.\n",
        "def word_rep(word, letter2index, device = 'cpu'):\n",
        "    rep = torch.zeros( len(word)+1, 1, len(letter2index) ).to(device)     # rows = no of words, cols = no of letters( here no of English letters)\n",
        "    # Getting a word and processing each letter from it to modify the 'Rep' Tensor.\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        rep[letter_index][0][pos] = 1\n",
        "    # Adding one-hot encoding of Pad char at the end.\n",
        "    pad_pos = letter2index[pad_char]\n",
        "    rep[letter_index+1][0][pad_pos] = 1\n",
        "    return rep\n",
        "\n",
        "# One hot Representation of Hindi word.\n",
        "def gt_rep(word, letter2index, device = 'cpu'):\n",
        "    gt_rep = torch.zeros( [len(word)+1, 1], dtype=torch.long).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]      # Getting the pos of letter in letter2index.\n",
        "        gt_rep[letter_index][0] = 1\n",
        "    gt_rep[letter_index+1][0] = letter2index[pad_char]\n",
        "    return gt_rep"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MUP75BJzT8O"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3eA0UiYxlJj",
        "outputId": "21f57a3d-0a33-4d57-d276-090f50a170aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "eng, hindi = train_data.get_random_sample()\n",
        "eng_rep = word_rep(eng, eng_alpha2index)\n",
        "print(eng, eng_rep)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BURMESTER tensor([[[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4P-i1EXxwvH",
        "outputId": "84d701d7-427e-4066-db0c-cb53587c3d35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "hindi_gt = gt_rep(hindi, hindi_alpha2index)\n",
        "print(hindi, hindi_gt)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "बर्मेस्टर tensor([[1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05F1-FwX6YVZ"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EKixOtzan57"
      },
      "source": [
        "def infer(net, word, max_output_char, device = 'cpu'):\n",
        "    out = net.forward(word_rep(word, eng_alpha2index), max_output_chars = max_output_char)\n",
        "    return out"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3TWC7zhAn3z"
      },
      "source": [
        "def test(net, word, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    outputs = infer(net, word, 30)\n",
        "    hindi_outputs = ''\n",
        "\n",
        "    for out in outputs:\n",
        "        val, indices = out.topk(1)  # Getting the top1 accuracy with its value and index.\n",
        "        index = indices.tolist()[0][0]\n",
        "        if index == 0:\n",
        "            break\n",
        "        hindi_char = hindi_alphabets[index+1]\n",
        "        hindi_outputs += hindi_char\n",
        "        \n",
        "    print(word + ' - ' + hindi_output)\n",
        "    return hindi_output \n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT8bibYl7CgX"
      },
      "source": [
        "def calc_accuracy(net, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    predictions = []\n",
        "    accuracy = 0\n",
        "    for i in range(len(test_data)):\n",
        "        eng, hindi = test_data[i]\n",
        "        gt = gt_rep(hindi, hindi_alpha2index, device)\n",
        "        outputs = infer(net, eng, gt.shape[0], device)\n",
        "        correct = 0\n",
        "        for index, out in enumerate(outputs):\n",
        "            val, indices = out.topk(1)\n",
        "            hindi_pos = indices.tolist()[0]\n",
        "            if hindi_pos[0] == gt[index][0]:\n",
        "                correct += 1\n",
        "        \n",
        "        accuracy += correct/gt.shape[0]\n",
        "    accuracy /= len(test_data)\n",
        "    return accuracy"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6VJfmdYzLwf"
      },
      "source": [
        "# Network Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QgRfuyZzTir"
      },
      "source": [
        "### Encoder-Decoder (using GRU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXPGTNcuzR9Q"
      },
      "source": [
        "MAX_OUTPUT_CHARS = 30\n",
        "\n",
        "class Transliteration_EncoderDecoder(nn.Module):\n",
        "\n",
        "    # input size = no of english char(26), output size = no of hindi char(100+)\n",
        "    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
        "        super(Transliteration_EncoderDecoder, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "        self.decoder_rnn_cell = nn.GRU(output_size, hidden_size) \n",
        "\n",
        "        self.h2o = nn.Linear(hidden_size, output_size)  # From hidden layer of Decoder cell to output.\n",
        "        self.softmax = nn.LogSoftmax(dim = 2)\n",
        "\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "        \n",
        "        # Encoder\n",
        "        out, hidden = self.encoder_rnn_cell(input)\n",
        "\n",
        "        if self.verbose:\n",
        "            print('Encoder input', input.shape)\n",
        "            print('Encoder output', out.shape)\n",
        "            print('Encoder hidden', hidden.shape)\n",
        "\n",
        "        # Decoder \n",
        "        decoder_state = hidden          # is equal to the last hidden rep that is being as first state to the decoder.\n",
        "        decoder_input = torch.zeros(1,1, self.output_size).to(device)\n",
        "        outputs = []\n",
        "\n",
        "\n",
        "        if self.verbose:\n",
        "            print('Decoder state', decoder_state.shape)\n",
        "            print('Decoder input', decoder_input.shape)\n",
        "        \n",
        "        # Decoder is looped through each char\n",
        "        for i in range(max_output_chars):\n",
        "\n",
        "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "\n",
        "            if self.verbose:\n",
        "                print('Decoder intermediate output', out.shape)\n",
        "            \n",
        "            # Input and State for the invocation\n",
        "            out = self.h2o(decoder_state)\n",
        "            out = self.softmax(out)\n",
        "            outputs.append(out.view(1,-1))\n",
        "\n",
        "            if self.verbose:\n",
        "                print('Decoder output', out.shape)\n",
        "                self.verbose = False\n",
        "            \n",
        "            # Look at Teacher Forcing concept\n",
        "            # Here instead of taking the output from decoder cell and giving it to next invocation, \n",
        "            # we would instead initially in the training give the ground truth's encoding and send to the decoder, \n",
        "            # later on we can send the value output by the cell itself.\n",
        "\n",
        "            max_idx = torch.argmax(out, 2, keepdim= True)\n",
        "            if not ground_truth is None:\n",
        "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "            one_hot = torch.FloatTensor(out.shape).to(device)\n",
        "            one_hot.zero_()\n",
        "            one_hot.scatter_(2, max_idx, 1)\n",
        "\n",
        "            detached_input = one_hot.detach()   # Detach is used so that backpropogation here does not happen and is not recorded.\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plSEOemCjHYb"
      },
      "source": [
        "net = Transliteration_EncoderDecoder( len(eng_alpha2index), 256, len(hindi_alpha2index), verbose = True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zWFXgM-nnUV",
        "outputId": "367ada6f-a35b-4db0-f901-d4562b633fbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "out = infer(net, 'SHAM', 30)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder input torch.Size([5, 1, 27])\n",
            "Encoder output torch.Size([5, 1, 256])\n",
            "Encoder hidden torch.Size([1, 1, 256])\n",
            "Decoder state torch.Size([1, 1, 256])\n",
            "Decoder input torch.Size([1, 1, 129])\n",
            "Decoder intermediate output torch.Size([1, 1, 256])\n",
            "Decoder output torch.Size([1, 1, 129])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ7N5pphrPow",
        "outputId": "0967e379-25c6-4d38-f50f-64bc819305ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "print(len(out))\n",
        "for i in range(len(out)):\n",
        "    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTs9VR2Yf_NP"
      },
      "source": [
        "### Encoder Decoder using Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49x8HOWYiWQy"
      },
      "source": [
        "class Transliteration_EncoderDecoder_Attention(nn.Module):\n",
        "\n",
        "    # input size = no of english char(26), output size = no of hindi char(100+)\n",
        "    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
        "        super(Transliteration_EncoderDecoder_Attention, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.encoder_cell = nn.GRU(input_size, hidden_size)\n",
        "        self.decoder_cell = nn.GRU(hidden_size*2, hidden_size)   # hidden_size * 2 since we augment the existing representation with the attention.\n",
        "\n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim = 2)\n",
        "\n",
        "        self.U = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.W = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "\n",
        "        self.attn = nn.Linear(self.hidden_size, 1)\n",
        "        # Output from decoder is converted to hidden_size\n",
        "        self.out2hidden = nn.Linear(self.output_size, self.hidden_size)\n",
        "\n",
        "        self.verbose = verbose\n",
        "    \n",
        "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "\n",
        "        # encoder\n",
        "        encoder_outputs, hidden = self.encoder_cell(input)\n",
        "        encoder_outputs = encoder_outputs.view(-1, self.hidden_size)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Encoder output', encoder_outputs.shape)\n",
        "        \n",
        "        # decoder\n",
        "        decoder_state = hidden\n",
        "        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
        "        \n",
        "        outputs = []\n",
        "        U = self.U(encoder_outputs)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Decoder state', decoder_state.shape)\n",
        "            print('Decoder intermediate input', decoder_input.shape)\n",
        "            print('U * Encoder output', U.shape)\n",
        "        \n",
        "        for i in range(max_output_chars):\n",
        "            \n",
        "            W = self.W(decoder_state.view(1, -1).repeat(encoder_outputs.shape[0], 1))\n",
        "            V = self.attn(torch.tanh(U + W))\n",
        "            attn_weights = F.softmax(V.view(1, -1), dim = 1) \n",
        "            \n",
        "            if self.verbose:\n",
        "                print('W * Decoder state', W.shape)\n",
        "                print('V', V.shape)\n",
        "                print('Attn', attn_weights.shape)         # Attn_weights is the alpha value.\n",
        "\n",
        "            if self.verbose:\n",
        "                print('W * Decoder state', W.shape)\n",
        "                print('V', V.shape)\n",
        "                print('Attn', attn_weights.shape)\n",
        "\n",
        "            # Applying attention with attn_weights and encoder outputs.\n",
        "            attn_applied = torch.bmm( attn_weights.unsqueeze(0), \n",
        "                                    encoder_outputs.unsqueeze(0) )\n",
        "\n",
        "            # Now the GRU has everything to run its GRU cell.\n",
        "            # Combing the attention with prev decoder output to send to the next decoder layer.\n",
        "            embedding = self.out2hidden(decoder_input)\n",
        "            decoder_input = torch.cat((embedding[0], attn_applied[0]), 1).unsqueeze(0)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Attn LC', attn_applied.shape)\n",
        "                print('Decoder input', decoder_input.shape)\n",
        "\n",
        "            # Compute the output.\n",
        "            out, decoder_state = self.decoder_cell(decoder_input, decoder_state)\n",
        "\n",
        "            if self.verbose:\n",
        "                print('Decoder intermediate output', out.shape)\n",
        "\n",
        "            out = self.h2o(decoder_state)\n",
        "            out = self.softmax(out)\n",
        "            outputs.append(out.view(1, -1))\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder output', out.shape)\n",
        "                self.verbose = False\n",
        "\n",
        "            # Finding the one-hot encoded vector and detaching it.\n",
        "\n",
        "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "            if not ground_truth is None:\n",
        "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "            one_hot = torch.zeros(out.shape, device=device)\n",
        "            one_hot.scatter_(2, max_idx, 1) \n",
        "            \n",
        "            decoder_input = one_hot.detach()\n",
        "            \n",
        "        return outputs\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfEysh7t53D2"
      },
      "source": [
        "net_attn = Transliteration_EncoderDecoder_Attention( len(eng_alpha2index), 256, len(hindi_alpha2index), verbose=True )"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZtrNhBL6Dcj",
        "outputId": "0d5766c3-88b0-4650-e260-e57f2c68563f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "out = infer(net_attn, 'INDIA', 30)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output torch.Size([6, 256])\n",
            "Decoder state torch.Size([1, 1, 256])\n",
            "Decoder intermediate input torch.Size([1, 1, 129])\n",
            "U * Encoder output torch.Size([6, 256])\n",
            "W * Decoder state torch.Size([6, 256])\n",
            "V torch.Size([6, 1])\n",
            "Attn torch.Size([1, 6])\n",
            "W * Decoder state torch.Size([6, 256])\n",
            "V torch.Size([6, 1])\n",
            "Attn torch.Size([1, 6])\n",
            "Attn LC torch.Size([1, 1, 256])\n",
            "Decoder input torch.Size([1, 1, 512])\n",
            "Decoder intermediate output torch.Size([1, 1, 256])\n",
            "Decoder output torch.Size([1, 1, 129])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5TuVcdf6Jh8",
        "outputId": "bb49bed4-64fb-4df8-b05f-01d6ad7870f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "print(len(out))\n",
        "for i in range(len(out)):\n",
        "    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "torch.Size([1, 129]) ब\n",
            "torch.Size([1, 129]) ॠ\n",
            "torch.Size([1, 129]) ॠ\n",
            "torch.Size([1, 129]) ॠ\n",
            "torch.Size([1, 129]) ॠ\n",
            "torch.Size([1, 129]) ॠ\n",
            "torch.Size([1, 129]) ॠ\n",
            "torch.Size([1, 129]) ॠ\n",
            "torch.Size([1, 129]) ॠ\n",
            "torch.Size([1, 129]) ॠ\n",
            "torch.Size([1, 129]) ॠ\n",
            "torch.Size([1, 129]) ॠ\n",
            "torch.Size([1, 129]) ८\n",
            "torch.Size([1, 129]) ॠ\n",
            "torch.Size([1, 129]) ॠ\n",
            "torch.Size([1, 129]) ॠ\n",
            "torch.Size([1, 129]) ॠ\n",
            "torch.Size([1, 129]) ८\n",
            "torch.Size([1, 129]) ब\n",
            "torch.Size([1, 129]) ॠ\n",
            "torch.Size([1, 129]) ॠ\n",
            "torch.Size([1, 129]) ॠ\n",
            "torch.Size([1, 129]) ॠ\n",
            "torch.Size([1, 129]) ॠ\n",
            "torch.Size([1, 129]) ॠ\n",
            "torch.Size([1, 129]) ॠ\n",
            "torch.Size([1, 129]) ॠ\n",
            "torch.Size([1, 129]) ८\n",
            "torch.Size([1, 129]) ॠ\n",
            "torch.Size([1, 129]) ॠ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dxc0Ec5Gu_CP"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3706c9s6vAuw"
      },
      "source": [
        "### Core Trainer (for 1 batch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpAEfAt_vEfb"
      },
      "source": [
        "def train_batch(net, opt, criterion, batch_size, device = 'cpu', teacher_force = False):\n",
        "    \n",
        "    net.train().to(device)\n",
        "    opt.zero_grad()\n",
        "    eng_batch, hindi_batch = train_data.get_batch(batch_size)\n",
        "    \n",
        "    total_loss = 0\n",
        "    for i in range(batch_size):\n",
        "        \n",
        "        input = word_rep(eng_batch[i], eng_alpha2index, device)\n",
        "        gt = gt_rep(hindi_batch[i], hindi_alpha2index, device)\n",
        "        outputs = net(input, gt.shape[0], device, ground_truth = gt if teacher_force else None)\n",
        "        \n",
        "        for index, output in enumerate(outputs):\n",
        "            loss = criterion(output, gt[index]) / batch_size\n",
        "            loss.backward(retain_graph = True)\n",
        "            total_loss += loss\n",
        "        \n",
        "    opt.step()\n",
        "    return total_loss/batch_size"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbnWa3DZw0YI"
      },
      "source": [
        "### Training Helper (for the total data in batches)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4l85G9Vwzw5"
      },
      "source": [
        "def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq=5, device = 'cpu'):\n",
        "    \n",
        "    net = net.to(device)\n",
        "    criterion = nn.NLLLoss(ignore_index = -1)\n",
        "    opt = optim.Adam(net.parameters(), lr=lr)\n",
        "    teacher_force_upto = n_batches//3\n",
        "    \n",
        "    loss_arr = np.zeros(n_batches + 1)\n",
        "    \n",
        "    for i in range(n_batches):\n",
        "        loss_arr[i+1] = (loss_arr[i]*i + train_batch(net, opt, criterion, batch_size, device = device, teacher_force = i<teacher_force_upto ))/(i + 1)\n",
        "        \n",
        "        if i%display_freq == display_freq-1:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            print('Iteration', i, 'Loss', loss_arr[i])\n",
        "            plt.figure()\n",
        "            plt.plot(loss_arr[1:i], '-*')\n",
        "            plt.xlabel('Iteration')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.show()\n",
        "            print('\\n\\n')\n",
        "            \n",
        "    torch.save(net, 'model.pt')\n",
        "    return loss_arr"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7HmCyCFyCfI"
      },
      "source": [
        "### Training without Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oQ3ZIWvtjfN"
      },
      "source": [
        "net = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6LjVKQfoVMU",
        "outputId": "33cb122d-4b83-4cba-abd2-5ffb7ef71b73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "train_setup(net, lr=0.001, n_batches=2000, batch_size = 64, display_freq=10, device = device_gpu)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1999 Loss 0.023624403402209282\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAcbElEQVR4nO3df3RddZnv8fcnSZsAbWqxCRRaTNHSsaICxooDVSoOUnUKozMKOh0dnYXemYoO46pVWK5ZXJwRXOO9soZ1p9wZxh8g+GuU3gsFgUEt3qE0ZQpSEVtKLQVKC2VoS2naJM/9Y+8TTtKTNGmzz0ny/bzWysrZ37PP3k/2Sc6T78+tiMDMzNJVV+sAzMystpwIzMwS50RgZpY4JwIzs8Q5EZiZJa6h1gEM17Rp06Ktra3WYZiZjSlr1659LiJaKj035hJBW1sbHR0dtQ7DzGxMkfS7gZ5z05CZWeKcCMzMEudEYGaWOCcCM7PEORGYmSUumUSwfdc+PrT8P9i+e1+tQzEzG1WSSQTX3rOBB57Yyfuvvc/JwMyszJibRzBcc65YSWdXT+/29t2dzPvKPTQ21PHYVQtrGJmZ2egw7msEq5YuoE4Hl3d29TDnipXVD8jMbJQZ94mgtbmJC087sU9ZfZ244LQTWPWFBTWKysxs9Bj3iQDgpf1dtEya2Lvd3RNMbmygdXJTDaMyMxsdkkgEyxe309r8yof+7NZJ7NjTWcOIzMxGjyQSwZwrVrL+6V292xu27+HO9c+6j8DMjIITgaTzJT0maaOkZRWe/7ikHZLW5V9/UUQcq5Yu4E0zpvRu1wv3EZiZ5QobPiqpHrgO+ANgK7BG0oqI+HW/Xb8XEUuKigNg/jX39hlC2h1w67qnueORbR5CambJK7JGMA/YGBGbImI/cAtwQYHnG9CqpQuYUP/KGNI6wfQpTa4RmJlR7ISyE4Eny7a3Am+rsN8HJb0D+C3w1xHxZP8dJF0CXAJw0kknDSuI/hPKAHoCnt21z6OGzMyofWfx/wHaIuJNwF3AtyrtFBHXR0R7RLS3tFS809qABppQ1hO4s9jMjGITwVPAzLLtGXlZr4h4PiJK4zj/GXjLSAdRaUIZuLPYzKykyESwBpgtaZakicBFwIryHSRNL9tcBDxaRCA/WffUQWW3rnua+VffW8TpzMzGlML6CCKiS9IS4E6gHrghItZLuhLoiIgVwKWSFgFdwE7g40XE0lBXx/7unoPKo4iTmZmNMYoYWx+H7e3t0dHRMazXlO5FsPn5vb1lkxrr+ffPn+MOYzNLgqS1EdFe6bladxZXRWtzU58kALCns5t5X7nHHcZmlrwkEgHAOadM4/gpjb3bdZ5dbGYGJJQIvvmJt3HazKkAiGz4qFcgNTNLKBEA7H75AJB1EnsFUjOzTDKJYM4VK/nl48/3bnsFUjOzTDKJYNXSBbznDcf1bjdNqHMfgZkZCSWC1uYmmpsm9G7vO9DjPgIzMxJKBAAv7N3f+9h9BGZmmWQSwZwrVnL3o9t7t91HYGaWSSYRrFq6gEWnndC77T4CM7NMMomgtbmJyY3Z0kr1gs4u9xGYmUGxN6YZdZ7b00nThDrOmdPCtElN7Ni9r9YhmZnVXDI1AoDli9uZevRE1jzxApee+zqWL664/pKZWVKSSgQAL3V28fxL+7n27g21DsXMbFRIpmmo/72Lb1y9hRtXb6GxoY7HrlpYw8jMzGormRpBadSQ8vsXe9SQmVkmmURQGjUUAfKoITOzXsk0DUE2auj45kZedfRE2tuO9aghMzMSSwTLF7fz5//6AM/t2c9VF55a63DMzEaFZJqGSnp6go3b97DdtQEzMyDBRPDE83t5+UC3h4+ameWSaRry8FEzs8qSqRGUho/We/iomVkfySSC0vDR7si2PXzUzCyTTCKAbPjonOMmcczEej76ttf4xjRmZiSWCJYvbuedc1rpCbjqwlO96JyZGYklAoCGOnGgu+fQO5qZJSK5RLC/q4eunuDZFz2PwMwMEkwEHb/bCcD/vOe3NY7EzGx0SHYewc0PPMnNDzzpeQRmlrxkagSleQQN+USCpgbPIzAzg4ITgaTzJT0maaOkZYPs90FJIamwYTy98wjyiQSd3Z5HYGYGBSYCSfXAdcBCYC5wsaS5FfabDHwWWF1ULCXP7enkzJNfDcCFp53oeQRmZhRbI5gHbIyITRGxH7gFuKDCfv8duBoofBjP8sXtfOitMwD47LmzPY/AzIxiE8GJwJNl21vzsl6SzgBmRsRtgx1I0iWSOiR17Nix44iCaqjLfmTPJTAzy9Sss1hSHfB14G8OtW9EXB8R7RHR3tLSckTn3dvZDcC2XZ5HYGYGxSaCp4CZZdsz8rKSycCpwM8kbQbOBFYU2WEMcMf6ZwC4afWWIk9jZjZmFDmPYA0wW9IssgRwEfCR0pMR8SIwrbQt6WfA5yOio4hg+s8juOORbbQtu83zCMwseYXVCCKiC1gC3Ak8Cnw/ItZLulLSoqLOO5DSPIKJ9dmPPLHe8wjMzKDgmcURcTtwe7+yLw+w7zlFxlKaR1DqJD7geQRmZkBCM4shm0ew8NTjAXjnnBbPIzAzI6G1hiCbR/Cbbbu4/ZFtfLh9JgvfOL3WIZmZ1VxSNQKACXkfwX7PIzAzA1JMBPmEsm/cvYHtuz2XwMwsvUTQkK0++sRzL3Ht3RtqHI2ZWe0l1UdQPpcggBtXb+HG1Vs8l8DMkpZUjWDV0gW9o4YAmiZ4LoGZWVKJoLW5ieamCQDU14nOLs8lMDNLqmkI4IW9+wH4yLyTCGCHO4zNLHHJJYLli9/CyV+6nalHT+Cy8+bUOhwzs5pLqmkIQBINdeIHa7d6+KiZGQkmAoCI4JkX93n4qJkZiTUN9V+K2sNHzcwSqxGUlqIu8fBRM7PEEkFpKWqAOuHho2ZmJNY0BNlS1JMa62lvO5YZU4/28FEzS15SNQLIlqJumdTIQ0/+F5ee+zqWLy70FslmZqNecokA4L9ePsALew941JCZGYk1DXnUkJnZwZKqEZRGDdVlK1F71JCZGYklgtKooZ4A4VFDZmaQWNMQZKOGpk9pYnLTBObNOtajhswseUnVCCAbNfS6lmPYunOvRw2ZmZFgIgDYvHMvew90e9SQmRmJNQ151JCZ2cGSqhGURg3Ve9SQmVmvpBJBadRQd2TbHjVkZpZYIoBs1NBrpx1NveADp89gx57OWodkZlZTySWC5YvbmdBQT3fAURPqPGrIzJLnzmJ3FptZ4pKqEZQ6ixvyNSbcWWxmVnAikHS+pMckbZS0rMLzn5b0K0nrJN0naW6R8ZQ6i7t6st5idxabmRWYCCTVA9cBC4G5wMUVPui/GxFvjIjTgGuArxcVT8lzezo59YRmAC548wnuLDaz5BVZI5gHbIyITRGxH7gFuKB8h4jYVbZ5DBAFxgNkncWNDdmPPbHBncVmZkV2Fp8IPFm2vRV4W/+dJP0VcBkwEXhXpQNJugS4BOCkk0467ID6dxZ/v2Mr3+/Y6s5iM0tazTuLI+K6iHgt8AXgigH2uT4i2iOivaWl5bDPVeosnpBPLW5scGexmVmRieApYGbZ9oy8bCC3ABcWGE9vZ/GBbncWm5mVDCkRSDpGUl3++BRJiyRNOMTL1gCzJc2SNBG4CFjR77izyzbfBxS+HGjpfgQAJx17lDuLzSx5Q+0j+AUwX9JU4KdkH/IfBj460AsiokvSEuBOoB64ISLWS7oS6IiIFcASSe8GDgAvAB87/B/l0Pr3EWzZ+TJbdr7MnCtWuo/AzJKliEMP1JH0YEScIekzwFERcY2kdfmwz6pqb2+Pjo6Ow3rt9l37uOr2R7njkW3s7+phYn0dC994PJe/7/VuHjKzcU3S2oioOExyqH0EkvR2shrAbXlZ/UgEV029fQR5reBAt/sIzMyGmgg+B3wR+HHevHMycG9xYRXnuT2dLHrzCQBMbmpg6wt7axyRmVltDamPICJ+DvwcIO80fi4iLi0ysKIsX9zOMy++zK0PPc3ufV3MmHp0rUMyM6upISUCSd8FPg10k3UUN0v6RkR8rcjgilDeYRx4BVIzs6E2Dc3Nl4O4EFgJzAIWFxZVgVYtXcD73zS9d7uxQZ5UZmZJG2oimJDPG7gQWBERB6jCukBFaG1uYspRr0yB6OwKdxibWdKGmgiWA5vJFob7haTXALsGfcUoNeeKldy0ekufshtXb2HOFStrFJGZWW0NKRFExLURcWJEvDcyvwPGZFtKab2hEt+cxsxSN9QlJqZI+rqkjvzrH8hqB2NOaS5Byb4DnktgZmkbatPQDcBu4EP51y7gX4sKqmjP7ensXYF0duskrzdkZkkb6hITBy0nMRaXmICD1xsq8fBRMxvPRmKJiZclnV12wLOAl0ciuGor9REo3/bwUTNL3VBXH/008G1JU/LtwlcKLUqpj6BUD/LwUTNL3VCXmHgIeLOk5nx7l6TPAQ8XGVwRKjUN3bh6Cz9Yu9VNQ2aWpGHdoSwidpXdcP6yAuIpXKlpqPSDu2nIzFJ3JLeq1KF3GX1KTUOlOoGbhswsdUeSCMbkEhOeWWxm1tegiUDSbkm7KnztBk4Y7LWjValpKJ9G4KYhM0veoJ3FETG5WoFUS6lpqDuvz7hpyMxSdyRNQ2OSm4bMzPpKLhGUmoYm5m1DAt7zhuPcNGRmyUouEfTewD5vGwpg046X3DRkZslKLhEA3PzAlj5DnjZs30PbstvcPGRmSUoyEdz/xXP5g9e39m7XC48cMrNkJZkI5l9zL3c9ur13uzvg1nVPM//qe2sYlZlZbSSZCFYtXcDxzY2923WC6VOaXCMwsyQlmQham5s49/XH9W73BJz7e63uMDazJCWZCDyXwMzsFUkmgv43sHdnsZmlbKg3phlX5l9zb597EpQ6i+94ZJvvSWBmyUm2RnD8lMY+Ze4sNrNUFZoIJJ0v6TFJGyUtq/D8ZZJ+LelhSfdIek2R8ZTMv+Zetr3Y2afsmRf3efiomSWpsEQgqR64DlgIzAUuljS3327/CbRHxJuAHwLXFBVPOdcIzMxeUWSNYB6wMSI2RcR+4BbggvIdIuLeiNibb94PzCgwnl6uEZiZvaLIRHAi8GTZ9ta8bCCfBCqO35R0iaQOSR07duw44sAq1QhaJze6RmBmSRoVncWS/hRoB75W6fmIuD4i2iOivaWl5YjPV6lGsH13p2sEZpakIhPBU8DMsu0ZeVkfkt4NXA4siojO/s8XYdXSyv/5d3b1eFKZmSWnyESwBpgtaZakicBFwIryHSSdDiwnSwLbKxyjEK3NTXzg9INbqTypzMxSVFgiiIguYAlwJ/Ao8P2IWC/pSkmL8t2+BkwCfiBpnaQVAxxuxP1k3UGVE69AamZJUkQceq9RpL29PTo6Oo74ONt37WPRdff16SuYPqWJW5ec5cXnzGzckbQ2ItorPTcqOotrwUNIzcwyySaCgSpCY6t+ZGZ25JJNBPd9YQFtrz66T1nbq4/mPncWm1likk0E86+5l83P7+1Ttvn5vW4aMrPkJJsI3DRkZpZJNhHc94UFqEL5fk8qM7PEJJsIWpubBvzv37UCM0tJsokA4JxTpjGpsb5PmTuMzSw1SSeC/9i0kz2d3X3K3GFsZqlJOhG4w9jMLPFEYGZmTgRmZslzIjAzS1zSiWCg0UGeS2BmKUk6EbQ2D7zctDuMzSwVSSeCwezv6ql1CGZmVZF8IphQX2mhiYHLzczGm+QTgSquOASSE4GZpSH5ROAOYzNLXfKJYLAO4073E5hZApJPBAADtQK5n8DMUuBEwMBrDh3o9iBSMxv/nAjwyCEzS5sTAfDLL7yrYvmB7qBt2W1VjsbMrLqcCBi8w9jMbLxzIjAzS5wTQe72S88e8Dk3D5nZeOZEkJt7wpRah2BmVhNOBGZmiXMiKDPYcFE3D5nZeFVoIpB0vqTHJG2UtKzC8++Q9KCkLkl/XGQsQzHQMFIzs/GssEQgqR64DlgIzAUuljS3325bgI8D3y0qjuHwMFIzS1GRNYJ5wMaI2BQR+4FbgAvKd4iIzRHxMDBqVnd7y0mvGvA5Nw+Z2XhUZCI4EXiybHtrXjaq/egvz6p1CGZmVTUmOoslXSKpQ1LHjh07Cj/fYEsMuVZgZuNNkYngKWBm2faMvGzYIuL6iGiPiPaWlpYRCW4wj//9+wo/h5nZaFFkIlgDzJY0S9JE4CJgRYHnG1GDXRjXCsxsPCksEUREF7AEuBN4FPh+RKyXdKWkRQCS3ippK/AnwHJJ64uKZ7g2fXXwWoFvY2lm40VDkQePiNuB2/uVfbns8RqyJqMxx7exNLPxYkx0FtfK5kPUCtxEZGbjgRPBIRzqLmVOBmY21jkRHMKGr7z3kPvM/pKTgZmNXU4EQ/CeNxw36PMHepwMzGzsciIYguWL22md3DjoPgd63ExkZmOTE8EQPXD5u9Hg3QVAlgy2795XfEBmZiPEiWAYnhjijON5X7mH//vwYU2iNjOrOieCYTrUkNKSJd9dR9uy27hvY/FrI5mZHQkngsMw1GQA8Kf//ACznBDMbBRzIjhMm7/6viH1GQAEWUJoW3Yby3++odC4zMyGSxFR6xiGpb29PTo6OmodRq9TrljJ/sNcbuIfP3Ia73/TqL9Fg5mNA5LWRkR7xeecCEbGkQ4d/bs/egMfeVvbyARjZtaPE0GVzPvK3Wzf3XnExxHwnb+Yx9mvK/7eC2aWBieCKpv1xdsY6cv6mXedzN+c9/qRPaiZJcOJoEaKSAj9uUnJzIbCiaDGPvWdDu5c/2zVz/vFhafwqXfOrvp5zWz0cSIYRY5klFERTpjSxE+WnEXr5KZah2JmBXIiGKVqVVM4UjOnHsWP/vL3nTzMxhAngjFitNUWqmFivfjJkrOYO31KrUMxG9ecCMYwL209stxvYqlyIhhnRmq+go0NnoFuI8GJICFjtd/BbKS52bEvJwI7iJuczMaexnrx48NMboMlgoYjjszGpOEspV3i5GFWW53dwWdvXsddl71zRI/rGoHVhJOK2ZEbzj90rhHYqHM4NZLD5X4TG2+mNDVw86fOHLHjORHYuLd8ccV/gka1FOeU2NC1NjeNaCe4E4HZKPTbqxbWOoQxqxqLPdbaiy8fGNHjORGY2bjyxN9Xr9lxvPA9i83MEudEYGaWuEITgaTzJT0maaOkZRWeb5T0vfz51ZLaiozHzMwOVlgikFQPXAcsBOYCF0ua22+3TwIvRMTrgP8BXF1UPGZmVlmRNYJ5wMaI2BQR+4FbgAv67XMB8K388Q+BcyWpwJjMzKyfIhPBicCTZdtb87KK+0REF/Ai8Or+B5J0iaQOSR07duwoKFwzszSNieGjEXE9cD2ApB2SfneYh5oGPDdigY0cxzV8ozU2xzU8jmt4jiSu1wz0RJGJ4ClgZtn2jLys0j5bJTUAU4DnBztoRLQcbkCSOgZaa6OWHNfwjdbYHNfwOK7hKSquIpuG1gCzJc2SNBG4CFjRb58VwMfyx38M/HuMtVXwzMzGuMJqBBHRJWkJcCdQD9wQEeslXQl0RMQK4F+A70jaCOwkSxZmZlZFhfYRRMTtwO39yr5c9ngf8CdFxtDP9VU813A4ruEbrbE5ruFxXMNTSFxj7n4EZmY2srzEhJlZ4pwIzMwSl0wiONS6RwWfe6akeyX9WtJ6SZ/Ny/9W0lOS1uVf7y17zRfzWB+T9J4CY9ss6Vf5+TvysmMl3SVpQ/59al4uSdfmcT0s6YyCYppTdk3WSdol6XO1uF6SbpC0XdIjZWXDvj6SPpbvv0HSxyqdawTi+pqk3+Tn/rGkV+XlbZJeLrtu/1T2mrfk7//GPPYjmtk/QFzDft9G+u91gLi+VxbTZknr8vJqXq+BPhuq+zsWEeP+i2zU0uPAycBE4CFgbhXPPx04I388Gfgt2fpLfwt8vsL+c/MYG4FZeez1BcW2GZjWr+waYFn+eBlwdf74vcBKQMCZwOoqvXfbyCbDVP16Ae8AzgAeOdzrAxwLbMq/T80fTy0grvOAhvzx1WVxtZXv1+84D+SxKo99YQFxDet9K+LvtVJc/Z7/B+DLNbheA302VPV3LJUawVDWPSpMRDwTEQ/mj3cDj3LwchvlLgBuiYjOiHgC2Ej2M1RL+RpQ3wIuLCv/dmTuB14laXrBsZwLPB4Rg80mL+x6RcQvyIY29z/fcK7Pe4C7ImJnRLwA3AWcP9JxRcRPI1uqBeB+skmcA8pja46I+yP7NPl22c8yYnENYqD3bcT/XgeLK/+v/kPAzYMdo6DrNdBnQ1V/x1JJBENZ96gqlC21fTqwOi9aklfxbihV/6huvAH8VNJaSZfkZcdFxDP5423AcTWIq+Qi+v6B1vp6wfCvTy2u2yfI/nMsmSXpPyX9XNL8vOzEPJZqxDWc963a12s+8GxEbCgrq/r16vfZUNXfsVQSwaggaRLwI+BzEbEL+F/Aa4HTgGfIqqfVdnZEnEG2XPhfSXpH+ZP5fz41GWOsbEb6IuAHedFouF591PL6DETS5UAXcFNe9AxwUkScDlwGfFdScxVDGnXvWz8X0/efjapfrwqfDb2q8TuWSiIYyrpHhZI0geyNviki/g0gIp6NiO6I6AH+N680Z1Qt3oh4Kv++HfhxHsOzpSaf/Pv2aseVWwg8GBHP5jHW/Hrlhnt9qhafpI8D7wc+mn+AkDe9PJ8/XkvW/n5KHkN581EhcR3G+1bN69UAfAD4Xlm8Vb1elT4bqPLvWCqJYCjrHhUmb4P8F+DRiPh6WXl5+/ofAaURDSuAi5TdwW0WMJusk2qk4zpG0uTSY7LOxkfouwbUx4Bby+L6s3zkwpnAi2XV1yL0+U+t1terzHCvz53AeZKm5s0i5+VlI0rS+cBSYFFE7C0rb1F2oygknUx2fTblse2SdGb+O/pnZT/LSMY13Petmn+v7wZ+ExG9TT7VvF4DfTZQ7d+xI+nxHktfZL3tvyXL7pdX+dxnk1XtHgbW5V/vBb4D/CovXwFML3vN5Xmsj3GEIxMGietkshEZDwHrS9eF7J4Q9wAbgLuBY/Nykd117vE87vYCr9kxZCvRTikrq/r1IktEzwAHyNpdP3k414eszX5j/vXnBcW1kayduPQ79k/5vh/M3991wIPAH5Ydp53sg/lx4B/JVxsY4biG/b6N9N9rpbjy8m8Cn+63bzWv10CfDVX9HfMSE2ZmiUulacjMzAbgRGBmljgnAjOzxDkRmJklzonAzCxxTgSWLEl78u9tkj4ywsf+Ur/t/zeSxzcbSU4EZtlqk8NKBPmM1MH0SQQR8fvDjMmsapwIzOCrwHxla8//taR6ZWv7r8kXSvsUgKRzJK2StAL4dV72k3zBvvWlRfskfRU4Kj/eTXlZqfah/NiPKFvX/sNlx/6ZpB8qu6fATfmsU7PCFXrzerMxYhnZevnvB8g/0F+MiLdKagR+Kemn+b5nAKdGtmwywCciYqeko4A1kn4UEcskLYmI0yqc6wNki6+9GZiWv+YX+XOnA28AngZ+CZwF3DfyP65ZX64RmB3sPLL1XNaRLQn8arL1ZgAeKEsCAJdKeohs/f+ZZfsN5Gzg5sgWYXsW+Dnw1rJjb41scbZ1ZE1WZoVzjcDsYAI+ExF9Fu2SdA7wUr/tdwNvj4i9kn4GNB3BeTvLHnfjv0+rEtcIzGA32W0CS+4E/lu+PDCSTslXZ+1vCvBCngR+j+zWgSUHSq/vZxXw4bwfooXsFopFrpRqdkj+j8MsW/mxO2/i+SbwDbJmmQfzDtsdVL4l4R3ApyU9SrZ65v1lz10PPCzpwYj4aFn5j4G3k634GsDSiNiWJxKzmvDqo2ZmiXPTkJlZ4pwIzMwS50RgZpY4JwIzs8Q5EZiZJc6JwMwscU4EZmaJ+//WJg+hTFS9NQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.49932772, 0.52027702, ..., 0.02362817, 0.0236244 ,\n",
              "       0.02362252])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YQVy_nayD80"
      },
      "source": [
        "### Training with Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxFLBqW1Ip4v"
      },
      "source": [
        "net_att = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index), 256, len(hindi_alpha2index))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdRpJUXNIwuv",
        "outputId": "a40ecbe9-d3ef-4104-a1be-410c593f28cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "loss_history = train_setup(net_att, lr=0.001, n_batches=2000, batch_size = 64, display_freq=10, device = device_gpu)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1999 Loss 0.022310759872198105\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy1bQiORAs5o",
        "outputId": "a459e833-f349-48e7-82b2-a3896a14fecc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "accuracy = calc_accuracy(net) * 100\n",
        "accuracy_attn = calc_accuracy(net_att) * 100\n",
        "print('Accuracy w/o attention ', accuracy)\n",
        "print('Acurracy with attention', accuracy_attn)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy w/o attention  91.01779775779796\n",
            "Acurracy with attention 90.74685037185057\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}